{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Learning - Linear Dimension Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Subset Selection](#subset-selection)\n",
    "   - [Best Subset Selection](#best-subset-selection)\n",
    "   - [Forward Stepwise Selection](#fwd-stepwise-selection)\n",
    "   - [Backward Stepwise Selection](#bwd-stepwise-selection)\n",
    "   - [Choosing the Optimal Model](#choosing-best)\n",
    "\n",
    "\n",
    "### [Shrinkage Methods](#shrinkage)\n",
    "   - [Ridge Regression](#ridge)\n",
    "   - [Lasso Regression](#lasso)\n",
    "   \n",
    "   \n",
    "### [Dimension Reduction Methods](#dimension-reduction)\n",
    "   - [Principal Components Regression](#pcr)\n",
    "   - [Partial Least Squares](#pls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as mpe\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import combinations\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Credit Dataset_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Asian</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Asian</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Limit  Rating  Cards  Age  Education  Gender  Student  Married  \\\n",
       "0   14.891   3606     283      2   34         11       1        0        1   \n",
       "1  106.025   6645     483      3   82         15       0        1        1   \n",
       "2  104.593   7075     514      4   71         11       1        0        0   \n",
       "3  148.924   9504     681      3   36         11       0        0        0   \n",
       "4   55.882   4897     357      2   68         16       1        0        1   \n",
       "\n",
       "   Ethnicity  Balance  \n",
       "0  Caucasian      333  \n",
       "1      Asian      903  \n",
       "2      Asian      580  \n",
       "3      Asian      964  \n",
       "4  Caucasian      331  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred = pd.read_csv(\"data/credit.csv\")\n",
    "cred.drop([\"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "cred[\"Student\"].replace({\"Yes\": 1, \"No\": 0}, inplace = True)\n",
    "cred[\"Married\"].replace({\"Yes\": 1, \"No\": 0}, inplace = True)\n",
    "cred[\"Gender\"].replace({\" Male\": 1, \"Female\": 0}, inplace = True)\n",
    "cred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"subset-selection\"></a>\n",
    "# Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il processo di *subset selection* ha l'obiettivo di individuare il corretto sottoinsieme di predittori da associare alla *response*. Esistono diversi approcci possibili."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"best-subset-selection\"></a>\n",
    "## Best Subset Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E' necessario addestrare una regressione lineare per ciascuna combinazione possibile dei $p$ *predictors*. In parole povere, si fittano tutti i $p$ modelli che contengono un solo predittore, tutti i $\\binom{p}{2}$ modelli che contengono esattamente due predittori, tutti i $\\binom{p}{3}$ modelli che contengono esattamente tre predittori e così via."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riassumiamo la *best subset selection* in forma algoritmica:\n",
    "\n",
    "- Si parte dal *null model* $M_0$, che non contiene predittori e restituisce sempre la *mean response* per ogni input.\n",
    "\n",
    "\n",
    "- Per $k=1,\\dots,p$:\n",
    "   - Si fittano i $\\binom{p}{k}$ modelli che contengono $k$ predittori.\n",
    "   - Si individua il modello che fitta meglio il training set e lo si denota con $M_k$. La metrica di riferimento per valutare il fit del training set è la *RSS* o l'*R-squared*.\n",
    "\n",
    "\n",
    "- Ora che si hanno a disposizione i modelli $M_0,\\dots,M_p$, si individua il migliore di questi usando la *CV*, l'*AIC*, il *BIC* o l'*Adjusted-R-squared*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La *best subset selection* è concettualmente semplice, ma soffre di limitazioni computazionali. Anche solo con 10 predittori, bisogna valutare 1000 modelli diversi!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fwd-stepwise-selection\"></a>\n",
    "## Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si inizia con il *null model* e si aggiungono predittori uno alla volta fin quando tutti sono inclusi nel modello. Ad ogni step, però, si aggiunge al modello solo la variabile che fornisce il maggior incremento addizionale al fitting dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riassumiamo la *forward stepwise selection* in forma algoritmica:\n",
    "\n",
    "- Si parte dal *null model* $M_0$, che non contiene predittori e restituisce sempre la *mean response* per ogni input.\n",
    "\n",
    "\n",
    "- Per $k=0,\\dots,p-1$:\n",
    "   - Ho già a disposizione il modello $M_k$. Si addestrano tutti i $p-k$ modelli che derivano dall'aggiunta di un ulteriore predittore rispetto a quelli contenuti in $M_k$.\n",
    "   - Scelgo il migliore fra questi $p-k$ modelli e lo chiamo $M_{k+1}$. Il modello migliore è quello che meglio fitta i dati di training, quindi lo individuo analizzando i valori di *RSS* o *R-Squared*.\n",
    "   \n",
    "   \n",
    "- Ora che si hanno a disposizione i modelli $M_0,\\dots,M_p$, si individua il migliore di questi usando la *CV*, l'*AIC*, il *BIC* o l'*Adjusted-R-squared*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al posto di addestrare $2^p$ modelli come nella *best subset selection*, in questo caso si fittano $p-k$ modelli ad ogni iterazione, con $k$ che aumenta ad ogni step fino a raggiungere $p-1$. In totale, si tratta di $1+p(p+1)/2$ modelli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifichiamo che questo approccio non garantisce l'individuazione del sottoinsieme di predittori ideali, cioè non ha la certezza di restituire il migliore fra tutti i $2^p$ modelli possibili. \n",
    "\n",
    "Facciamo un esempio: se ho tre predittori e il miglior modello univariato contiene $X_1$, tutti i modelli successivi conterranno sempre $X_1$; è possibile, però, che il miglior modello bivariato sia quello contenente $X_2$ e $X_3$, e la procedura non sarà mai in grado di individuarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"bwd-stepwise-selection\"></a>\n",
    "## Backward Stepwise Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si parte dal *full model* contenente tutti i predittori, e ad ogni step si rimuove quello che sembra fornire il peggior contributo al fitting dei dati di training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riassumiamo la *backward stepwise selection* in forma algoritmica:\n",
    "\n",
    "- Si parte dal *full model* $M_p$, che contiene tutti i predittori.\n",
    "\n",
    "\n",
    "- Per $k=p,p-1,p-2,\\dots,1$:\n",
    "   - Ho già a disposizione il modello $M_p$. Si addestrano tutti i $k$ modelli che derivano dalla rimozione di uno dei predittori già contenuti in in $M_k$.\n",
    "   - Scelgo il migliore fra questi $k$ modelli e lo chiamo $M_{k-1}$. Il modello migliore è quello che meglio fitta i dati di training, quindi lo individuo analizzando i valori di *RSS* o *R-Squared*.\n",
    "   \n",
    "   \n",
    "- Ora che si hanno a disposizione i modelli $M_0,\\dots,M_p$, si individua il migliore di questi usando la *CV*, l'*AIC*, il *BIC* o l'*Adjusted-R-squared*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche in questo caso il numero totale di modelli analizzati è $1+p(p+1)/2$, e anche in questo caso non c'è garanzia di individuare il migliore fra i $2^p$ modelli totali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"choosing-best\"></a>\n",
    "## Choosing the Optimal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tutti gli approcci proposti è sempre presente uno step incentrato sull'individuazione del modello che meglio lavora sui dati di test. Ci sono due tecniche per risolvere tale problema:\n",
    "\n",
    "- Stimare *indirettamente* il *test error* applicando una sorta di *adjustment* al *training error*, che tenga conto dell'overfitting e del numero di predittori.\n",
    "\n",
    "\n",
    "- Stimare *direttamente* il *test error* usando la *cross-validation*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo dimostrato come il *training MSE* non sia altro che una sottostima del *test MSE*. Esistono però delle metriche che sfruttano la *RSS* di *training* per costruire una più affidabile del *test error*: *Mallow's $C_p$*, *Akaike Information Criterion*, *Bayesian Information Criterion* e *Adjusted R-squared*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per un modello con $d$ predittori, la stima del *test MSE* prodotta dal **Mallow's $C_p$** deriva dalla seguente formulazione:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large C_p=\\frac{1}{n}\\left(RSS+2d\\hat{\\sigma}^2\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il valore $\\hat{\\sigma}^2$ è una stima della variabilità dell'*error term* $\\epsilon$ associato a ciascuna misurazione della *response*. In genere, tale stima si costruisce a partire dal *full model* e non dal modello a $d$ predittori per il quale si sta calcolando il *test MSE*.\n",
    "\n",
    "Notiamo come $C_p$ aggiunga una penalità alla *training RSS* in modo da compensare la decrescita nativa di *RSS* all'aggiunta di nuovi predittori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per un modello con $d$ predittori, la stima del *test MSE* prodotta dall'**Akaike Information Criterion** deriva dalla seguente formulazione:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large AIC=\\frac{1}{n\\hat{\\sigma}^2}\\left(RSS+2d\\hat{\\sigma}^2\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essendo proporzionali fra loro, spesso solo uno fra l'*AIC* e il *Cp* è riportato nelle analisi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per un modello con $d$ predittori, la stima del *test MSE* prodotta dal **Bayesian Information Criterion** deriva dalla seguente formulazione:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large BIC=\\frac{1}{n\\hat{\\sigma}^2}\\left(RSS+log(n)d\\hat{\\sigma}^2\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siccome $log(n)>2$ per qualsiasi $n>7$, è possibile osservare come la *BIC* applichi una penalità maggiore a modelli con più variabili, e quindi porti il processo di *model selection* a isolare modelli mediamente più piccoli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per un modello con $d$ predittori, la stima del *test MSE* prodotta dall'**Adjusted $R^2$** deriva dalla seguente formulazione:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large Adj.R^2=1-\\frac{RSS/(n-d-1)}{TSS/(n-1)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al contrario del *Cp*, dell'*AIC* e del *BIC*, che assumono valori bassi per indicare un basso *test error*, l'*Adjusted R-squared* assume valori alti per indicare modelli molto performanti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **cross-validation** rappresenta un valido rivale per le quattro metriche appena descritte. Ci sono tre vantaggi chiave: la *CV* calcola direttamente una stima del *test error*, compie meno assunzioni sul modello sottostante e può essere usate per una gran varietà di task, specialmente in quelli in cui è molto difficile stimare la variabilità dell'*error term* $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le metriche appena descritte sono diventate famose perché non gravano sul processo dal punto di vista computazionale, al contrario della *CV*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usiamo la **CV** e la **stepwise forward selection** per individuare il miglior set di predittori del dataset *credit*, che ha come *response* la variabile *balance*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Balance</th>\n",
       "      <th>Ethnicity_African American</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Caucasian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>903</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Limit  Rating  Cards  Age  Education  Gender  Student  Married  \\\n",
       "0   14.891   3606     283      2   34         11       1        0        1   \n",
       "1  106.025   6645     483      3   82         15       0        1        1   \n",
       "2  104.593   7075     514      4   71         11       1        0        0   \n",
       "3  148.924   9504     681      3   36         11       0        0        0   \n",
       "4   55.882   4897     357      2   68         16       1        0        1   \n",
       "\n",
       "   Balance  Ethnicity_African American  Ethnicity_Asian  Ethnicity_Caucasian  \n",
       "0      333                           0                0                    1  \n",
       "1      903                           0                1                    0  \n",
       "2      580                           0                1                    0  \n",
       "3      964                           0                1                    0  \n",
       "4      331                           0                0                    1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = cred.copy()\n",
    "df = pd.get_dummies(df, columns=[\"Ethnicity\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"Balance\"\n",
    "X = df.drop(response, axis = 1)\n",
    "Y = df[response]\n",
    "\n",
    "k = len(X.columns)\n",
    "\n",
    "remaining_features = list(X.columns)\n",
    "best_features = list()\n",
    "r2_list = list()\n",
    "features_dict = dict()\n",
    "\n",
    "for i in range(1, k + 1):\n",
    "    best_r2 = 0\n",
    "    for combo in combinations(remaining_features, 1):\n",
    "        model = LinearRegression()\n",
    "        model.fit(X[list(combo) + best_features], Y)\n",
    "        r2 = model.score(X[list(combo) + best_features], Y)\n",
    "        \n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_feature = combo[0]\n",
    "\n",
    "    best_features.append(best_feature)\n",
    "    remaining_features.remove(best_feature)\n",
    "    \n",
    "    r2_list.append(best_r2)\n",
    "    features_dict[i] = best_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preds</th>\n",
       "      <th>features</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rating</td>\n",
       "      <td>0.745848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rating-Income</td>\n",
       "      <td>0.875118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rating-Income-Student</td>\n",
       "      <td>0.949879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rating-Income-Student-Limit</td>\n",
       "      <td>0.952188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards</td>\n",
       "      <td>0.954161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age</td>\n",
       "      <td>0.954688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender</td>\n",
       "      <td>0.954817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.954933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.955014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.955066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.955102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.955102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_preds                                           features        R2\n",
       "0           1                                             Rating  0.745848\n",
       "1           2                                      Rating-Income  0.875118\n",
       "2           3                              Rating-Income-Student  0.949879\n",
       "3           4                        Rating-Income-Student-Limit  0.952188\n",
       "4           5                  Rating-Income-Student-Limit-Cards  0.954161\n",
       "5           6              Rating-Income-Student-Limit-Cards-Age  0.954688\n",
       "6           7       Rating-Income-Student-Limit-Cards-Age-Gender  0.954817\n",
       "7           8  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.954933\n",
       "8           9  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.955014\n",
       "9          10  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.955066\n",
       "10         11  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.955102\n",
       "11         12  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.955102"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame({\"num_preds\": list(features_dict.keys()),\n",
    "                          \"features\": [\"-\".join(v) for k, v in features_dict.items()],\n",
    "                          \"R2\": r2_list})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo aver individuato i migliori modelli per ciascun numero di predittori, usiamo la *CV* per trovare quello che performa meglio sui dati di test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(response, axis = 1)\n",
    "Y = df[response]\n",
    "\n",
    "cv = KFold(n_splits = 10, shuffle = True, random_state = 888)\n",
    "\n",
    "test_mse_list = list()\n",
    "\n",
    "for features in features_dict.values():\n",
    "    errors = list()\n",
    "    X_feats = X[features]\n",
    "    \n",
    "    for train_idx, test_idx in cv.split(X):\n",
    "        X_train, X_test = np.array(X_feats)[train_idx], np.array(X_feats)[test_idx]\n",
    "        Y_train, Y_test = np.array(Y)[train_idx], np.array(Y)[test_idx]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, Y_train)\n",
    "        errors.append(mean_squared_error(Y_test, model.predict(X_test)))\n",
    "    test_mse_list.append(np.mean(errors))\n",
    "result_df[\"Test MSE\"] = test_mse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_preds</th>\n",
       "      <th>features</th>\n",
       "      <th>R2</th>\n",
       "      <th>Test MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age</td>\n",
       "      <td>0.954688</td>\n",
       "      <td>9961.655565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender</td>\n",
       "      <td>0.954817</td>\n",
       "      <td>9967.686292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards</td>\n",
       "      <td>0.954161</td>\n",
       "      <td>9997.186362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.954933</td>\n",
       "      <td>10019.342119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.955014</td>\n",
       "      <td>10027.230548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.955066</td>\n",
       "      <td>10055.047179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.955102</td>\n",
       "      <td>10106.516999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Rating-Income-Student-Limit-Cards-Age-Gender-E...</td>\n",
       "      <td>0.955102</td>\n",
       "      <td>10106.516999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rating-Income-Student-Limit</td>\n",
       "      <td>0.952188</td>\n",
       "      <td>10409.898442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Rating-Income-Student</td>\n",
       "      <td>0.949879</td>\n",
       "      <td>10830.443518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rating-Income</td>\n",
       "      <td>0.875118</td>\n",
       "      <td>26923.680594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Rating</td>\n",
       "      <td>0.745848</td>\n",
       "      <td>54380.195259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_preds                                           features        R2  \\\n",
       "5           6              Rating-Income-Student-Limit-Cards-Age  0.954688   \n",
       "6           7       Rating-Income-Student-Limit-Cards-Age-Gender  0.954817   \n",
       "4           5                  Rating-Income-Student-Limit-Cards  0.954161   \n",
       "7           8  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.954933   \n",
       "8           9  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.955014   \n",
       "9          10  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.955066   \n",
       "11         12  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.955102   \n",
       "10         11  Rating-Income-Student-Limit-Cards-Age-Gender-E...  0.955102   \n",
       "3           4                        Rating-Income-Student-Limit  0.952188   \n",
       "2           3                              Rating-Income-Student  0.949879   \n",
       "1           2                                      Rating-Income  0.875118   \n",
       "0           1                                             Rating  0.745848   \n",
       "\n",
       "        Test MSE  \n",
       "5    9961.655565  \n",
       "6    9967.686292  \n",
       "4    9997.186362  \n",
       "7   10019.342119  \n",
       "8   10027.230548  \n",
       "9   10055.047179  \n",
       "11  10106.516999  \n",
       "10  10106.516999  \n",
       "3   10409.898442  \n",
       "2   10830.443518  \n",
       "1   26923.680594  \n",
       "0   54380.195259  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sort_values(by = \"Test MSE\", ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il modello con 6 predittori è associato al valore più basso di *test MSE*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"shrinkage-methods\"></a>\n",
    "# Shrinkage Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I metodi di *subset selection* utilizzano il *least squares criterion* per addestrare un modello lineare contenente solo un sottoinsieme dei predittori totali. In alternativa, è possibile fittare un modello contenente tutti i predittori e applicare delle tecniche che *regolarizzino* o più semplicemente *riducano* i valori delle stime dei *model parameters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ridge\"></a>\n",
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il *least squares criterion* stima i coefficienti del modello lineare provando a minimizzare la *RSS*. Il problema di minimizzazione della *ridge regression* è leggermente diverso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large minimize_{\\beta_i}\\;\\; RSS+\\lambda\\sum_{j=1}^{p}\\beta_j^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il termino aggiunto è un **regularization term**, caratterizzato dal **regularization parameter** $\\lambda\\geq0$. Così come per il *LSC* originale, questo nuovo problema cerca le stime parametriche attraverso una minimizzazione della *RSS*, ma allo stesso tempo presenta una **shrinkage penalty** che può essere minimizzata solo se i *model coefficients* presentano valori vicini a zero.\n",
    "\n",
    "Il *tuning parameter* $\\lambda$ serve a controllare l'impatto relativo di questi due termini: se $\\lambda=0$, non c'è penalità, e la ridge produce le stesse stime del *LSC*; se $\\lambda\\rightarrow\\infty$, invece, l'impatto della penalità aumenta e le stime tendono a zero.\n",
    "\n",
    "Notiamo come la penalità non si applichi all'*intercept* $\\beta_0$, che rappresenta solo il valore medio della *response* quando i predittori sono nulli."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifichiamo, inoltre, che è meglio applicare la ridge dopo aver standardizzato i predittori, cioè dopo aver applicato la seguente trasformazione:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\tilde{x}_{ij}=\\frac{x_{ij}}\n",
    "{\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_{ij}-\\bar{x}_j)^2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il denominatore non è altro che la stima della deviazione standard del predittore *j-esimo*. Così facendo tutti i predittori presenteranno deviazione standard unitaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il vantaggio principale che ci porta ad utilizzare la ridge è legato al *bias-variance trade-off*: all'aumentare di $\\lambda$, infatti, diminuisce la flessibilità e di conseguenza la varianza, costringendo il bias ad aumentare.\n",
    "\n",
    "In realtà la decrescita di varianza è molto più pronunciata rispetto all'aumento di bias, almeno per i primi valori di $\\lambda$ dopo lo zero, aumentando la qualità predittiva del modello. Ad un certo punto, però, la decrescita di varianza tende a spegnersi, e la grossa penalità sui valori dei coefficienti causa un ampio aumento di bias nel modello.\n",
    "\n",
    "In generali, le stime del *LSC* tendono ad essere associate con bias molto basso ed alta varianza, in particolare quando la relazione *predictors-response* è realmente lineare. Quest'alta varianza si riscontra nel forte impatto che un piccolo cambio nel *training set* può avere nelle stime parametriche del modello.\n",
    "\n",
    "Di conseguenza, la ridge funziona particolarmente bene in situazioni in cui le stime del *LSC* sono associate ad alta variabilità!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lasso\"></a>\n",
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ridge ha un ovvio svantaggio, cioè include sempre tutti i predittori nel modello finale. La **L2 Penalty** che la caratterizza limita i valori di tutti i coefficienti, ma non è capace di fissarne alcuno ad esattamente zero. Questo non rappresenta un problema per l'accuratezza predittiva, ma può rivelarsi problematico ai fini della *model interpretation* se ci sono tanti predittori.\n",
    "\n",
    "La differenza fra ridge e lasso sta nella penalty:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large minimize_{\\beta_i}\\;\\; RSS+\\lambda\\sum_{j=1}^{p}|\\beta_j|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In altre parole, la lasso adotta la **L1 Penalty** e non la *L2 Penalty*. Analogamente alla ridge, la lasso è in grado di limitare i valori dei coefficienti del modello, ma è anche capace di annullarli completamente, a patto che $\\lambda$ sia sufficientemente grande.\n",
    "\n",
    "In altre parole, in maniera simile alle tecniche di *subset selection*, la lasso implementa una forma di *variable selection*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non è possibile affermare quale dei due metodi di regolarizzazione sia superiore all'altro. In generale, ci si aspetta che la lasso performi meglio in scenari in cui solo pochi predittori hanno dei coefficienti importanti, mentre tutti gli altri sono associati a valori piccoli o quasi nulli. La ridge, al contrario, funziona meglio quando la *response* è funzione di molti predittori, tutti con coefficienti di dimensioni confrontabili."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dimension-reduction\"></a>\n",
    "# Dimension Reduction Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tratta si una serie di tecniche usano delle versioni trasformate dei predittori per addestrare un modello lineare con il *least squares criterion*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siano $Z_1,\\dots,Z_M$ delle combinazioni lineari dei $p$ predittori originali, dove $M<p$. A livello matematico, vuol dire:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large Z_j=\\sum_{i=1}^{p}\\phi_{ij}X_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In altre parole, ciascun predittore contribuisce al calcolo di ogni singolo $Z_j$, i termini $\\phi_{ij}$ non sono altro che delle costanti che associano i diversi $Z_j$ ai predittori $X_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando questi nuovi predittori $Z_j$, possiamo addestrare una regressione lineare:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large y_i=\\theta_0+\\sum_{j=1}^{M}\\theta_jz_{ij}+\\epsilon_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ad esempio, con due predittori trasformati:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large y_i=\\theta_0+\\theta_1z_{i1}+\\theta_2z_{i2}+\\epsilon_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo approccio riduce il problema originale della stima di $p+1$ coefficienti $\\beta_0,\\dots,\\beta_p$ ad un problema più semplice in cui si devono stimare solo $M+1$ coefficienti $\\theta_0,\\dots,\\theta_M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esistono due tecniche principali che utilizzano quest'approccio: *principal components* e *partial least squares*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pcr\"></a>\n",
    "## Principal Components Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La *Principal Component Analysis* è una tecnica molto utilizzata in task di *unsupervised learning* per ricavare un insieme di *features* di bassa dimensione a partire da un insieme più grande di variabili. In questo caso, la utilizziamo come tecnica di *dimensionality reduction* per la regressione lineare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il cosiddetto **first principal component** è la *direzione* nei dati lungo la quale le osservazioni variano maggiormente. In altre parole, se proiettassimo le osservazioni su questa direzione/retta, l'insieme delle proiezioni risultanti presenterebbe la più grande varianza possibile rispetto a tutte le altre direzioni/rette."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/pcr-simple.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A livello matematico, il *first principal component* dell'esempio presentato segue la seguente formulazione:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large Z_1=0.839\\times(X_1-\\bar{X}_1)+0.544\\times(X_2-\\bar{X}_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le costanti $\\phi_{11}=0.839$ e $\\phi_{21}=0.544$ prendono il nome di **principal component loadings**.\n",
    "\n",
    "Se avessimo un dataset di $n=100$ osservazioni, dovremmo usare la formulazione del *first principal component* per costruire i cosiddetti **principal component scores** $z_{i1}$, che sarà ancora un array di 100 elementi e conterrà il valore delle osservazioni sul nuovo asse:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large z_{i1}=0.839\\times(X_{i1}-\\bar{X}_{i1})\n",
    "+0.544\\times(X_{i1}-\\bar{X}_{i1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'è anche un'altra interpretazione della PCA: il *first principal component* definisce la retta che si trova il più vicino possibile ai dati; a livello matematico, vuol dire che si tratta di quella retta che minimizza la somma delle distanze quadrate perpendicolari fra ciascun punto e la retta in questione. In parole povere, il *first principal component* è sempre scelto in modo che le osservazioni proiettate su di esso siano più vicine possibile alle osservazioni originali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo pensare che i valori di $Z_1$ siano una sorta di riassunto dei valori di $X_1$ e $X_2$ per ciascuna osservazione. Ma com'è possibile che un singolo numero rappresenti contemporaneamente due predittori? In questo caso, sembra che le due *feature* siano associate ad una forte relazione lineare, quindi ci possiamo aspettare che una metrica a singolo numero funzioni bene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo come ci sia una forte relazione lineare fra il *first PC* e le due *feature*; in altre parole, il *first PC* sembra in grado di inglobare gran parte dell'informazione contenuta nei due predittori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/pcr-first-corr.PNG\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo parlato solo del primo componente principale, ma tecnicamente potremmo costruire fino a $p$ *PC* distinti. Il secondo componente principale è una combinazione lineare di $X_1$ e $X_2$ che risulta non correlato con $Z_1$ e che, allo stesso tempo, presenta la maggior variabilità possibile rispetto alla proiezione delle osservazioni.\n",
    "\n",
    "La condizione di zero correlazione fra i due *PC* equivale a imporre che essi debbano essere perpendicolari fra loro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large Z_2=0.544\\times(X_1-\\bar{X}_1)-0.839\\times(X_2-\\bar{X}_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da notare come il primo *PC* conterrà sempre più informazioni di tutti gli altri *PC*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/pcr-second-corr.PNG\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **principal components regression** prevede la costruzione di $M$ *principal components* $Z_1,\\dots,Z_M$ e l'utilizzo di quest'ultimi per costruire un modello lineare utilizzando il *LSC*.\n",
    "\n",
    "L'idea di fondo della *PCR* è che dovrebbe bastare un piccolo numero di *PC* per spiegare gran parte della variabilità dei dati e, allo stesso tempo, la relazione dei predittori con la *response*.\n",
    "\n",
    "In altre parole, l'assunzione di fondo della *PCR* è che le direzioni in cui i predittori mostrano la maggiore variazione devono necessariamente essere le direzioni lungo le quali essi sono associati con la *response*. Nonostante tale assunzione non sia sempre verificata, si tratta di una buona approssimazione della realtà."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se l'assunzione centrale della *PCR* è rispettata, allora fittare un modello con $Z_1,\\dots,Z_M$ porterà a risultati migliori rispetto al fittare un modello con $X_1,\\dots,X_p$, dato che la quasi totalità delle informazioni sarà contenuta nei *PC* e usando meno *features* dovremmo essere in grado di mitigare l'*overfitting*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In generali, più *PC* sono utilizzati nella *PCR*, più il bias della procedura tende a scendere, ed aumenta la varianza. Questo, come visto per il *bias-variance trade-off* porta al tipico andamento *U-shape* del *Test MSE*.\n",
    "\n",
    "Specifichiamo che, nonostante la *PCR* ci porti ad addestrare un modello usando meno predittori, non si tratta di una tecnica di *feature selection*, in quanto in ciascuno dei nuovi $M$ predittori ci sarà un contributo di tutti i predittori originali.\n",
    "\n",
    "Ricordiamo, infine, che la standardizzazione dei predittori è fondamentale nella *PCR*, e che in genere il numero di *PC* è ricavato tramite *CV*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applichiamo la *PCR* sul dataset *Credit*, analizzando le configurazioni ottenibili al variare del numero di componenti principali:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(cred, columns=[\"Ethnicity\"])\n",
    "\n",
    "response = \"Balance\"\n",
    "X = df.drop(response, axis = 1)\n",
    "Y = df[response]\n",
    "cv = KFold(n_splits = 10, shuffle = True, random_state = 888)\n",
    "\n",
    "mse_list = list()\n",
    "\n",
    "for n_comps in range(1, len(X.columns) + 1):\n",
    "    pca = PCA(n_components = n_comps)\n",
    "    X_pca = pca.fit_transform(scale(X))\n",
    "    errors = list()\n",
    "    for train_idx, test_idx in cv.split(X):\n",
    "        X_train, X_test = np.array(X_pca)[train_idx], np.array(X_pca)[test_idx]\n",
    "        Y_train, Y_test = np.array(Y)[train_idx], np.array(Y)[test_idx]\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, Y_train)\n",
    "        errors.append(mean_squared_error(Y_test,\n",
    "                                         model.predict(X_test)))\n",
    "    mse_list.append(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (6, 3))\n",
    "ax.plot(np.arange(1, 13), mse_list)\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"CV MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pls\"></a>\n",
    "## Partial Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La *PCR* si basa sull'individuazione delle *directions* o combinazioni lineari che meglio rappresentano i predittori $X_1,\\dots,X_p$. Queste *directions* sono identificate in maniera non supervisionata, dato che la *response* non è usata per calcolarli.\n",
    "\n",
    "Per questo motivo la *PCR* soffre di un problema: non c'è garanzia che le *directions* che meglio spiegano la variabilità dei predittori siano anche quelle che meglio spiegano la variabilità della *response*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La **partial least squares** è un'alternativa supervisionata alla *PCR*.\n",
    "\n",
    "Come per la *PCR*, si identifica un nuovo insieme di *features* $Z_1,\\dots,Z_M$ costruite come combinazione lineare dei predittori originali, e si addestra un modello lineare con il *LSC*.\n",
    "\n",
    "La differenza è che la *PLS* utilizza la *response* per identificare i nuovi predittori, cioè cerca le combinazioni lineari che meglio spiegano la variabilità dei predittori e che allo stesso tempo sono correlati con la *response*. E' come dire che la *PLS* prova a trovare delle *directions* che spiegano contemporaneamente sia la *response* che i *predictors*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo aver standardizzato i predittori, la *PLS* calcola la prima direzione $Z_1$ settando le costanti $\\phi_{j1}$ uguali alla *slope* risultante da una regressione lineare di $Y$ su ciascun $X_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/pls.PNG\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nel plot precedente notiamo la prima *direction* della *PLS* come retta continua e il *first principal component* della *PCR* come retta tratteggiata. Si evidenzia come la *PLS* abbia scelto una *direction* che presenta minore variabilità per $X_2$ (*Ad Spending*) rispetto alla *PCR*; ciò vuol dire che probabilmente $X_1$ è maggiormente correlata con la *response*! In sostanza, le *directions* della *PLS* non fittano i predittori così bene, ma spiegano meglio la *response*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per identificare la seconda *directions* della *PLS* dobbiamo calcolare una regressione di ciascun'altra variabile su $Z_1$ e calcolarne i *residuals*. Tali residui possono essere interpretati come l'informazione rimanente che non è stata spiegata dalla prima *direction* della *PLS.\n",
    "\n",
    "Il processo può essere ripetuto $M$ volte fin quando, ottenuti tutti i predittori d'interesse, si addestra un modello lineare usando $Z_1,\\dots,Z_M$ per predire $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
